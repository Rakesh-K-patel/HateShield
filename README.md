# HateShield - Safeguarding Against Malice in Memes

Hateful memes present a challenge in today's digital communication due to their blend of images and text, making them difficult to detect using traditional methods. To address this, our thesis proposes a comprehensive system for identifying hateful memes swiftly and effectively.
Our approach combines advanced text and image analysis techniques, integrating both to capture subtle signs of hate speech. We introduce a novel feature expansion method that adds extra details from meme images, boosting the system's ability to spot harmful content.
At the heart of our method is a multimodal model that merges image and text features, making our system more accurate and robust. By bringing together insights from both words and pictures, we aim to create a safer online space.
Beyond just stopping mean memes, our research has broader implications for improving how we use technology to tackle online hate speech. By understanding how mean content spreads online, we hope to make the internet a kinder place for everyone.
